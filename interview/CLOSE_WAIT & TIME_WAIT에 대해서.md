# CLOSE_WAIT & TIME_WAIT에 대해서



## **왜 알아야하는가?**

트래픽이 많은 서비스를 운영하다보면 CPU는 여유가 있지만 웹 서버가 응답을 제대로 하지못하는 경우의 가장 대표적인 경우가 CLOSE_WAIT 이기 떄문에




통상적으로 시스템이 느려지거나 멈추는 현상을 행업 이라고 합니다.
\- Hang up이란 Server Instance는 실행되고 있으나, 아무런 응답이 없는 상황을 말합니다.
\- 비슷한 의미로 Slowdown이 있는데 Server Instance의 response time이 아주 급격히 떨어지는 상태를 의미합니다.

Hang up이나 slowdown 현상은 대부분이 Network, User Application, WEB/WAS(Servlet Engine), JVM, RDBMS 다섯가지 요소 중 하나 이상의 병목으로 인해서 발생합니다. 

------


# CLOSE_WAIT



## TCP에 대해서

![img](https://farm1.staticflickr.com/440/18338404268_f693b065d4_o.png)

1. 먼저 `close()`를 실행한 클라이언트가 `FIN`을 보내고 `FIN_WAIT1` 상태로 대기한다.
2. 서버는 `CLOSE_WAIT`으로 바꾸고 응답 `ACK`를 전달한다. 그와 동시에 해당 포트에 연결되어 있는 어플리케이션에게 `close()`를 요청한다.
3. `ACK`를 받은 클라이언트는 상태를 `FIN_WAIT2`로 변경한다.
4. `close()` 요청을 받은 서버 어플리케이션은 종료 프로세스를 진행하고 `FIN`을 클라이언트에 보내 `LAST_ACK` 상태로 바꾼다.
5. `FIN`을 받은 클라이언트는 `ACK`를 서버에 다시 전송하고 `TIME_WAIT`으로 상태를 바꾼다. `TIME_WAIT`에서 일정 시간이 지나면 `CLOSED`된다. `ACK`를 받은 서버도 포트를 `CLOSED`로 닫는다.



* 여기서 주의할 점은 항상 서버만이 CLOSE_WAIT 상태를 갖는 것이 아니라는 점이다.

------



## 그렇다면 CLOSE_WAIT을 강제로 종료하는 방법은?

FIN_WAIT 나 TIME_WAIT은 타임아웃 혹은 재사용이가능하지만 CLOSE_WAIT은 그렇지 않다. (타임아웃 불가 - 로컬 어플리케이션의 문제)

1. 포트를 잡고 있는 프로세스를 강제 종료
2. 네트워크 재시작



## 그럼 CLOSE_WAIT 원인은 뭐지

로컬은 행업 상태이기 때문에 검색 결과를 보내주지 못하고 결과를 기다리는 쓰레드는 계속 대기하게 된다. (동일한 WAS를 사용)

* 서로가 서로를 기다리는 상태 발생
  * 교착 생태 (Dead Lock)

------

# TIME_WAIT

TCP 상태의 가장 마지막 단계 

close()를 먼저 요청한 쪽에서 최종적으로 남게된다. (2*MSL 동안 유지)



## 만약 TIME_WAIT이 짧다면?

![image](https://user-images.githubusercontent.com/33277588/82812791-b9731500-9ece-11ea-822c-bf4287331031.png)



위와 같이 TIME_WAIT이 짧다고 가정해보자!

송신자는 FIN을 보내서 수신자와 통신을 한다. 하지만 수신측에서 보낸 ACK가 유실되어서 송신측은 자신이 보낸 FIN에 대한 ACK를 받지 못한 상황이 되었다.

송신자의 입장에서는 ACK를 받지 못했기 때문에 FIN을 다시 한번 보내게 되지만, 수신자의 입장에서는 이미 TIME_WAIT 상태의 소켓을 정리해 버렸기 때문에 송신자로부터 받은 FIN이 정상적인 FIN이라 판단하지 않고 RST를 보낸다. 송신측은 자신이 정리해야 하는 소켓에 대해 계속해서 정상적인 ACK를 받지 못하기 때문에 소켓이 LAST_ACK 상태로 계속해서 남아있게 된다. 그래서 비정상적인 LASK_ACK 상태의 소켓이 점점 증가할 수 있다.



반면에 위와 달리 TIME_WAIT이 길었다면 ACK가 유실되었다 하더라도 수신측에서 송신측의 FIN을 처리할 만한 충분한 시간동안 소켓이 TIME_WAIT상태로 살이있기 때문에 자신이 ACK를 보냈다고 하더라도 무언가 통신에 이상이 생겼음을 감지하고 송신측에 FIN에 대해 한번더 ACK를 보낼 수 있게 된다.

(FIN과 ACK의 재전송을 처리할 수 있는 기회를 얻게 된다.)

------



## TIME_WAIT은 시스템 성능 저하를 가져올까?



결론부터 말하자면 NO! 이다. 

STACKOVERFLOW나 오래된 TIME_WAIT 관련 성능저하 논문은 굉장히 오래된 이야기이며 요즘 서버 사양에는 들어맞지 않는다.

Time_Wait_Socket의 메모리는 고작 168바이트에 불과하며 4만개가 있다쳐도 10MB 안쪽이다.



### 서버는 로컬 포트를 사용하지 않는다.

서버가 로컬포트를 사용하고 로컬포트는 단 하나의 소켓에만 바인딩 될까?

> **틀린 정보**: 서버의 소켓 수는 할당 가능한 로컬 포트 만큼인 최대 65,535개이고 `net.ipv4.ip_local_port_range` 설정으로 변경할 수 있다.



* 로컬포트는 2^16-1 = 65,535개가 최대지만 TIME_WAIT은 9만개 이상 만들어 낼 수 있다.
  * 최초 바인딩된 포트만을 사용하요 패킷을 주고 받는다. (여러개의 포트사용 X)
* 서버가 할당하는것은 포트가 아닌 소켓 이다.
  * 로컬 포트를 할당하는 것은 클라이언트이며 connect()시 로컬 포트를 임의로 바인딩하면서 서버의 소켓과 연결한다.



서버가 할당하는 소켓의 수는 리눅스 파일 디스크립터만큼 생성이 가능하다. 



## 포트의 재사용

1. 서버에 `TIME_WAIT` 상태가 남아 있으며, 클라이언트의 로컬 포트가 고갈된 경우
2. 클라이언트에 `TIME_WAIT` 상태가 남아 있으며, 클라이언트의 로컬 포트가 고갈된 경우
3. 클라이언트에 `TIME_WAIT` 상태가 남아 있으며, 클라이언트의 로컬 포트가 고갈되고, 서버의 다른 포트에 접속할 경우





1번의 경우는 클라이언트입장에서 서버에 남아있는 TIME_WAIT상태를 알 수 없다. 따라서 클라이언트는 임의의 포트에 SYN 패킷을 내보낸다. 



2번의 경우에는 오류가 발생하여 더 이상 접속할 수 없다. 왜냐면 소켓은 <protocol>`, `<src addr>`, `<src port>`, `<dest addr>`, `<dest port>

해당 5개의 값으로 구성되는데 로컬 포트가 고갈되면 더 이상 유니크한 값을 만들어낼 수 없기 때문이다.

* `net.ipv4.tcp_tw_reuse` 옵션을 설정하여 기존 클라이언트에 `TIME_WAIT` 상태로 남아 있던 소켓을 재사용



3번의 경우에는 문제가 없다.서버의 다른 포트에 접속하기 때문에 새로운 소켓 쌍을 만들어 낼 수 있기 때문이다.



------

## 클라이언트에서의 TIME_WAIT



#### 클라이언트는 어떤 경우에 TIME_WAIT이 걸리는가? 

데이터 저장 및 가공을 위해 데이터베이스, 메모리 기반의 캐시 시스템들과 연동하기도 하고 외부 서비스와의 연동을 위해 API를 호출하기도 한다. **이런 과정에서 서비스를 제공하는 서버는 연동하는 시스템에 대해서는 클라이언트가 될 수 있다.**



클라이언트 가 TIME_WAIT이 발생했을때 가장 큰 문제는 **로컬 포트가 고갈**되는 것이다

* 클라이언트는 요청을 보내기 위해 소켓을 만든다. 이때 가용한 포트 중 하나를 임의로 배정 받아서 나가게 된다.



##### 예시

(1) DB 서버와 통신할 때 사용할 포트 요청 - 애플리케이션은 DB 서버와의 통신을 위해 커널에 소켓 생성을 요청한다.

(2) 가용한 로컬 포트를 찾아서 할당 (ex.35010) - 커널은 자신이 관리하고 있는 로컬 포트 목록 중에 사용할 수 있는 포트 번호 한 개를 애플리케이션 할당한다.

(3) 목적지 IP, 목적지 포트를 주고 할당받은 로컬 포트로 소켓 생성 요청 - 애플리케이션은 할당 받은 번호로 커널에 소켓 생성을 요청한다.

(4) 소켓 생성 - 커널은 해당 정보로 소켓을 생성한다. **소켓은 출발지 IP, 출발지 Port, 목적지 IP, 목적지 Port, 이 4개의 값을 한 묶음으로 해서 생성하며 해당 소켓은 커널 내부에 유일하게 존재한다. 즉 4개의 값이 동일한 또 다른 소켓은 존재하지 않는다.**

(5) 소켓 접근할 때 사용할 FD 제공 - 소켓 생성이 정상적으로 완료되면 커널은 애플리케이션에서 소켓 접근에 사용할 FD(File Descriptor)를 전달해 준다.



> 정리하자면 클라이언트 측에서 ACTIVE_CLOSE를 하게 되면 TIME_WAIT 상태로 남게된다.
>
> TIME_WAIT상태인 해당 소켓은 해당 상태가 종료되지 않는 이상 커널로 돌아갈 수 없다. 이러한 이유로 다량의 로컬 포트가 TIME_WAIT 상태로 쌓여 사용할 수 있는 포트가 고갈된다면 서버와 통신이 힘들어진다.

* <u>외부로의 요청에 TIME_WAIT 소켓이 쌓이면 더이상 할당할 수 있는 로컬 포트가 없어서 사용자의 요청을 처리할 수 없게 된다.</u>

  

#### 이러한 로컬 포트 고갈에 대응할 수 있는 방법은 없을까?

> ### **net.ipv4.tcp_tw_reuse** 의 사용



![image-20200526213343434](/Users/junwoochoi/Library/Application Support/typora-user-images/image-20200526213343434.png)

**Kernel은 net.ipv4.local_port_range 범위 안에서 임의의 값을 선택한 다음 TW Socket Array에 해당 값을 사용하는 동일한 쌍의 소켓이 있는지 확인한다. 이때 net.ipv4.tw_reuse 값이 켜져 있으면 해당 값을 사용하도록 그대로 리턴하고, 꺼져 있으면 다른 값을 선택해서 확인하는 과정을 다시 진행한다. 이를 통해서 net.ipv4.tcp_tw_reuse를 사용하면 TIME_WAIT 상태의 소켓을 재사용해서 외부로 요청을 보낸다.**

------



## 서버에서의 TIME_WAIT

이전에 언급하였듯이 서버는 로컬 포트를 사용하지 않는다. 서버는 소켓을 열어 놓고 요청을 받아들이는 입장이기 때문에 로컬 포트 고갈과 같은 문제는 일어나지 않느다.

다만 클리언트와 서버도 마찬가지로 다수의 TIME_WAIT 소켓이 존재하면 불필요한 연결 맺기/끊기 의 과정이 반복된다.



keepalive_timeout을 0으로 해서 서버를 올리고 클라이언트 측에서 서버에 요청을 보내면 서버는 다수의 TIME_WAIT 소켓이 발생한다.

> keepalive를 껐기 때문에 웹서버가 먼저 연결을 끊는다. 즉, 웹서버가 active close했기 때문에 웹서버에서 TIME_WAIT 소켓이 생긴다.



#### 서버의 TIME_WAIT 사태에 대응할 수 있는 방법은 없을까?

> #### **net.ipv4.tcp_tw_recycle** 의 사용



net.ipv4.tw_reuse는 나갈때 사용하는 로컬 포트에서 TIME_WAIT 상태의 소켓을 재사용할 수 있게 해주는 파라미터라고 설명했다. 

<u>**net.ipv4.tw_recycle은 그 반대로 서버 입장에서 TIME_WAIT 상태의 소켓을 빠르게 회수하고 재활용할 수 있게 해주는 파라미터이다.**</u>



![image](https://user-images.githubusercontent.com/33277588/82903082-61eeab00-9f9b-11ea-88f6-6327f98f8f62.png)

net.ipv4.tcp_tw_recycle이 켜지면 커널은 두가지 작업을 추가로 진행한다.

1. 가장 마지막에 해당 소켓으로 들어온 timestamp 저장

2. TIME_WAIT 소켓의 타이머를 RTO 기반의 값으로 변경

   

TIME_WAIT 소켓의 기본 타임아웃은 1분이다. 특히 2번 과정때문에 TIME_WAIT 소켓이 눈에 보일새도 없이 사라진다. RTO는 보통 ms 단위이기 때문이다. 하지만 1번과정 때문에 서비스에 문제가 생길 가능성이 있다.



C1과 C2가 동일한 통신사를 사용하는 클라이언트라고 가정해보자. 동일한 통신사를 사용하면 동일한 NAT를 사용할 수 있고 S 입장에서는 같은 목적지 IP를 달고 오기때문에 같은 클라이언트로 보게 된다. 같은 클라이언트가 출발지 포트만 다르게 해서 요청하는 것과 같다. S는 C1과의 통신을 잘 마무리하고 로직상에 구현되어 있는 대로 TIME_WAIT 소켓을 RTO 값으로 세팅해서 금방 정리하고, C1의 Timestamp를 저장한다. 그 후 C2가 다시 한번 연결 오픈 요청을 보내는데, 이때 C1과 C2는 동일한 클라이언트가 아니기 때문에 시간이 살짝 다를 수 있으며 이때 Timestamp 값이 C1이 보낸 FIN에 기록된 Timestamp보다 작을 수 있다.

* 즉 이전의 요청보다 타임스탬프가 작으면 서버는 오동작이라 간주하고 패킷을 드랍시킨다. 클라이언트는 자신이 전송한 패킷이 오동작인지를 확인할 방법이 없기떄문에 계속해서 요청이 올때까지 전송한다.

![image](https://user-images.githubusercontent.com/33277588/82904456-7764d480-9f9d-11ea-8d31-49615051002a.png)



#### keepalive를 사용해서 대체해보자

* keepalive는 한번 맺은 세션을 요청이 끝나더라도 유지해주는 기능



예를 들어 2초 간격으로 계속해서 GET 요청이 들어온다면 2초마다 한번씩 세션을 맺기보다는 하나의 세션을 연결해 놓고 그 연결을 유지하면서 지속적으로 요청을 처리하는 것이 서버 리소스 활용 면에서도 경제적이고, 서비스 응답 속도의 측면에서도 훨씬 도움이 된다. **불필요한 연결 맺기/끊기를 없애면, TPS가 높아질수록 성능이 더욱 좋아진다.**

